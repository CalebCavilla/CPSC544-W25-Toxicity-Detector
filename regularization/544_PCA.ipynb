{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KmEgrbG8sxI8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        },
        "id": "0C4azNBxtT93",
        "outputId": "26dbd423-0b90-49fc-cc5f-b1dfb23e782f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(159571, 84)\n",
            "(159571,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0\n",
              "1    0\n",
              "2    0\n",
              "3    0\n",
              "4    0\n",
              "Name: toxic, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>toxic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "X_data = pd.read_csv('features_DEMO.csv')\n",
        "y_data = pd.read_csv('train.csv')[\"toxic\"]\n",
        "\n",
        "print(X_data.shape) # important in colab, it will take partial data even if it is not fully read in\n",
        "print(y_data.shape)\n",
        "y_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8b0iSFQYuWbZ"
      },
      "outputs": [],
      "source": [
        "# from sklearn import preprocessing\n",
        "# X_data.fillna(0, inplace=True)\n",
        "# X_data_norm = preprocessing.normalize(X_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN1NIlKFC6uA",
        "outputId": "249c47ac-c8fa-4990-d86a-8e37656c5953"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "Best parameters: {'pca__n_components': 71}\n",
            "{'params': {'pca__n_components': 71}, 'score': np.float64(0.5528966514446323)}\n",
            "{'params': {'pca__n_components': 70}, 'score': np.float64(0.5528966300643695)}\n",
            "{'params': {'pca__n_components': 69}, 'score': np.float64(0.5527004875341309)}\n",
            "{'params': {'pca__n_components': 67}, 'score': np.float64(0.5520464866776376)}\n",
            "{'params': {'pca__n_components': 68}, 'score': np.float64(0.5518504510487126)}\n",
            "{'params': {'pca__n_components': 66}, 'score': np.float64(0.5517851343460879)}\n"
          ]
        }
      ],
      "source": [
        "# old code, built later stuff off of this\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('scaler', StandardScaler()),\n",
        "    ('pca', PCA()),\n",
        "    # ('lda', LinearDiscriminantAnalysis()), # worse with this\n",
        "    ('classification', LogisticRegression())\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'pca__n_components': [n for n in range(66, 72)],\n",
        "    # 'lda__solver': ['svd'], # others did not seem to make a difference\n",
        "    # 'lda__n_components': [1]\n",
        "}\n",
        "\n",
        "# used precision to focus on negatives\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='recall', verbose=1, n_jobs=-1)\n",
        "grid_search.fit(X_data, y_data)\n",
        "\n",
        "print(\"Best parameters:\", grid_search.best_params_)\n",
        "\n",
        "# sort the results to display the best params/models\n",
        "results = [\n",
        "    {\"params\": grid_search.cv_results_[\"params\"][i], \"score\": grid_search.cv_results_[\"mean_test_score\"][i]}\n",
        "    for i in range(len(grid_search.cv_results_[\"params\"]))\n",
        "]\n",
        "sorted_results = sorted(results, key=lambda x: x[\"score\"], reverse=True)\n",
        "\n",
        "for entry in sorted_results:\n",
        "    print(entry)\n",
        "\n",
        "# 0.81585 at 68 PCA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZxJNutRaWfrn"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "# from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # performed worse with this in the pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
        "\n",
        "class PCA_finder:\n",
        "  def __init__(self, X, y, classifier=LogisticRegression(), scoring_=\"recall\"):\n",
        "    # find values on construction. Save with method\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "    self.model, self.n_components, _ = self.find_best_pca_components(classifier, scoring=scoring_)\n",
        "    self.trans_X = self.model.named_steps[\"pca\"].transform(self.X)\n",
        "\n",
        "  ### Use cross validation on a pca pipeline, testing values of n_components until\n",
        "  ### improvements are bellow threshold self.tol.\n",
        "  def find_best_pca_components(self,\n",
        "                               classifier, tol=0.001,\n",
        "                               X=None, y=None,\n",
        "                               early_stopping=True,\n",
        "                               scoring=\"recall\"):\n",
        "    if X is None:\n",
        "      X = np.array(self.X)\n",
        "    if y is None:\n",
        "      y = self.y\n",
        "\n",
        "    # logging\n",
        "    logs = []\n",
        "\n",
        "    # tracking\n",
        "    best_score = -np.inf\n",
        "    best_n = 0\n",
        "    recommend_score = -np.inf\n",
        "    recommend_n = -1\n",
        "    model = None\n",
        "\n",
        "    for n in range(1, self.X.shape[1]):\n",
        "      model = Pipeline([\n",
        "          (\"scaler\", StandardScaler()),\n",
        "          (\"pca\", PCA(n_components=n)),\n",
        "          (\"model\", classifier)\n",
        "      ])\n",
        "      score = np.mean(cross_val_score(model, self.X, self.y, cv=5, scoring=self.scoring))\n",
        "      model.fit(self.X, self.y)\n",
        "\n",
        "      # logs\n",
        "      logs.append([model, n, score])\n",
        "\n",
        "      # track best score\n",
        "      if score > best_score:\n",
        "          best_score = score\n",
        "          best_n = n\n",
        "\n",
        "      # track recommended\n",
        "      if n>1 and abs(logs[n-1][2]-logs[n-2][2]) < tol:\n",
        "          recommend_n = n\n",
        "          recommend_score = score\n",
        "          if early_stopping:\n",
        "            break\n",
        "\n",
        "    if not early_stopping:\n",
        "      print(f\"Best number of components: {best_n} with {self.scoring} score: {best_score}\")\n",
        "    print(f\"Recommended number of components: {recommend_n} with {self.scoring} score: {best_score}\")\n",
        "    return logs[recommend_n-1]\n",
        "\n",
        "  def report_scores(self, X=None, y=None):\n",
        "    if X is None:\n",
        "      X = self.X\n",
        "    if y is None:\n",
        "      y = self.y\n",
        "\n",
        "    y_pred = self.model.predict(X)\n",
        "    f1 = f1_score(y, y_pred, average=\"macro\")\n",
        "    print(f\"f1_macro : {f1:.4}\")\n",
        "    accuracy = accuracy_score(y, y_pred)\n",
        "    print(f\"accuracy : {accuracy:.4}\")\n",
        "    precision = precision_score(y, y_pred)\n",
        "    print(f\"precision: {precision:.4}\")\n",
        "    recall = recall_score(y, y_pred)\n",
        "    print(f\"recall   : {recall:.4}\")\n",
        "\n",
        "  def get_model(self):\n",
        "    return self.model\n",
        "\n",
        "  def predict(self, X):\n",
        "    return self.model.predict(X)\n",
        "\n",
        "  def transform_data(self, X):\n",
        "    self.trans_X = self.model.named_steps[\"pca\"].transform(X)\n",
        "    return self.trans_X\n",
        "\n",
        "  def save_transformed_data(self, file_name=\"trans_X.csv\"):\n",
        "    if self.trans_X:\n",
        "      np.savetxt(file_name, self.trans_X, delimiter=\",\")\n",
        "\n",
        "  def save_model(self, file_name=\"model.pkl\"):\n",
        "    import pickle\n",
        "    with open(file_name, \"wb\") as f:\n",
        "      pickle.dump(self.model, f)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca_finder = PCA_finder(X_data, y_data, scoring_=\"recall\")\n",
        "pca_finder.report_scores()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZZoBxsVEg9w",
        "outputId": "2471dd7c-54da-4264-813a-4e1bf3052cc4"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recommended number of components: 11 with precision score: 0.7849373886220191\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but PCA was fitted without feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_macro : 0.7867\n",
            "accuracy : 0.9386\n",
            "precision: 0.7861\n",
            "recall   : 0.4939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sns.lineplot(x=components, y=scores)\n",
        "# plt.show()\n",
        "pca_finder.report_scores()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvI68ytO5qnV",
        "outputId": "8d1fae3d-59ea-451d-b4bc-937407fb8a30"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1_macro : 0.7869\n",
            "accuracy : 0.9387\n",
            "precision: 0.7861\n",
            "recall   : 0.4945\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}